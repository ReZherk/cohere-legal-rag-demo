"""
VisualizaciÃ³n de Embeddings y Similaridad

Este script muestra cÃ³mo funcionan los embeddings y la similaridad semÃ¡ntica
"""
import os
from dotenv import load_dotenv
from rag_system import LegalRAGSystem
import numpy as np


def visualizar_similaridades():
    """
    Muestra la similaridad entre diferentes queries y documentos
    """
    print("=" * 70)
    print("ğŸ” VISUALIZACIÃ“N DE EMBEDDINGS Y SIMILARIDAD SEMÃNTICA")
    print("=" * 70)
    
    load_dotenv()
    api_key = os.getenv("COHERE_API_KEY")
    
    if not api_key or api_key == "tu-api-key-aqui":
        print("\nâŒ ERROR: Configura tu COHERE_API_KEY en el archivo .env")
        return
    
    # Inicializar sistema
    print("\nğŸ“¦ Inicializando sistema y generando embeddings...")
    rag = LegalRAGSystem(api_key=api_key)
    rag.load_documents_from_folder("data/legal_docs")
    
    # Queries de prueba
    queries = [
        "Â¿CuÃ¡l es el plazo para apelar una sentencia?",
        "Â¿QuÃ© es un recurso de casaciÃ³n?",
        "ExplÃ­came cÃ³mo se cuentan los plazos procesales",
        "Â¿CÃ³mo hacer una pizza napolitana?",  # â† NO relevante (control)
    ]
    
    print("\n" + "=" * 70)
    print("ğŸ“Š ANÃLISIS DE SIMILARIDAD PARA DIFERENTES CONSULTAS")
    print("=" * 70)
    
    for query_idx, query in enumerate(queries, 1):
        print(f"\n{'â”€' * 70}")
        print(f"QUERY #{query_idx}: {query}")
        print(f"{'â”€' * 70}")
        
        # Generar embedding de la query
        query_response = rag.client.embed(
            texts=[query],
            model=rag.embed_model,
            input_type="search_query",
            embedding_types=["float"]
        )
        query_embedding = np.array(query_response.embeddings.float[0])
        
        # Calcular similaridades con todos los documentos
        similarities = rag._cosine_similarity(query_embedding, rag.document_embeddings)
        
        # Ordenar por similaridad
        sorted_indices = np.argsort(similarities)[::-1]
        
        # Mostrar resultados
        print("\nğŸ“ˆ Similaridad con cada documento:")
        for rank, idx in enumerate(sorted_indices, 1):
            doc = rag.documents[idx]
            score = similarities[idx]
            
            # VisualizaciÃ³n con barras
            bar_length = int(score * 50)  # Barra de hasta 50 caracteres
            bar = "â–ˆ" * bar_length + "â–‘" * (50 - bar_length)
            
            # Emoji segÃºn relevancia
            if score > 0.7:
                emoji = "ğŸŸ¢"
                label = "ALTA"
            elif score > 0.4:
                emoji = "ğŸŸ¡"
                label = "MEDIA"
            else:
                emoji = "ğŸ”´"
                label = "BAJA"
            
            print(f"  {emoji} #{rank} - {doc.metadata['source']:25s} | {bar} | {score:.4f} ({label})")
        
        # Determinar relevancia general
        max_sim = np.max(similarities)
        if max_sim > 0.7:
            conclusion = "âœ… Hay documentos MUY relevantes para esta consulta"
        elif max_sim > 0.4:
            conclusion = "âš ï¸  Hay documentos relacionados, pero no altamente relevantes"
        else:
            conclusion = "âŒ NO hay documentos relevantes (como era de esperar)"
        
        print(f"\n  ğŸ’¡ {conclusion}")


def comparar_queries_similares():
    """
    Compara queries que son semÃ¡nticamente similares pero con palabras diferentes
    """
    print("\n\n" + "=" * 70)
    print("ğŸ”¬ COMPARACIÃ“N DE QUERIES SEMÃNTICAMENTE SIMILARES")
    print("=" * 70)
    
    load_dotenv()
    api_key = os.getenv("COHERE_API_KEY")
    
    rag = LegalRAGSystem(api_key=api_key)
    
    # Pares de queries semÃ¡nticamente similares
    query_pairs = [
        (
            "Â¿CuÃ¡l es el plazo para apelar?",
            "Â¿CuÃ¡nto tiempo tengo para impugnar una sentencia?"
        ),
        (
            "Â¿QuÃ© es un recurso de casaciÃ³n?",
            "ExplÃ­came quÃ© significa recurso de casaciÃ³n"
        ),
    ]
    
    print("\nGenerando embeddings de queries...\n")
    
    for idx, (query1, query2) in enumerate(query_pairs, 1):
        print(f"{'â”€' * 70}")
        print(f"PAR #{idx}:")
        print(f"  Query A: {query1}")
        print(f"  Query B: {query2}")
        
        # Generar embeddings
        response = rag.client.embed(
            texts=[query1, query2],
            model=rag.embed_model,
            input_type="search_query",
            embedding_types=["float"]
        )
        
        emb1 = np.array(response.embeddings.float[0])
        emb2 = np.array(response.embeddings.float[1])
        
        # Calcular similaridad entre las queries
        # Normalizar
        emb1_norm = emb1 / np.linalg.norm(emb1)
        emb2_norm = emb2 / np.linalg.norm(emb2)
        
        # Similaridad
        similarity = np.dot(emb1_norm, emb2_norm)
        
        # Visualizar
        bar_length = int(similarity * 50)
        bar = "â–ˆ" * bar_length + "â–‘" * (50 - bar_length)
        
        print(f"\n  Similaridad: {bar} {similarity:.4f}")
        
        if similarity > 0.9:
            print(f"  ğŸ’š PrÃ¡cticamente idÃ©nticas semÃ¡nticamente")
        elif similarity > 0.7:
            print(f"  ğŸ’› Muy similares (mismo tema)")
        else:
            print(f"  ğŸ§¡ Relacionadas pero diferentes enfoques")
        
        print()


def mostrar_dimensiones_embedding():
    """
    Muestra informaciÃ³n sobre las dimensiones de los embeddings
    """
    print("\n\n" + "=" * 70)
    print("ğŸ“ INFORMACIÃ“N SOBRE DIMENSIONES DE EMBEDDINGS")
    print("=" * 70)
    
    load_dotenv()
    api_key = os.getenv("COHERE_API_KEY")
    
    rag = LegalRAGSystem(api_key=api_key)
    
    # Generar embedding de ejemplo
    response = rag.client.embed(
        texts=["Ejemplo de texto"],
        model=rag.embed_model,
        input_type="search_query",
        embedding_types=["float"]
    )
    
    embedding = np.array(response.embeddings.float[0])
    
    print(f"\nğŸ“Š Modelo: {rag.embed_model}")
    print(f"ğŸ“ Dimensiones: {len(embedding)}")
    print(f"ğŸ“ˆ Rango de valores: [{embedding.min():.4f}, {embedding.max():.4f}]")
    print(f"ğŸ“‰ Valor promedio: {embedding.mean():.4f}")
    print(f"ğŸ“ Norma (magnitud): {np.linalg.norm(embedding):.4f}")
    
    print("\nğŸ’¡ Primeros 10 valores del embedding:")
    print(f"   {embedding[:10]}")
    
    print("\nğŸ“š ExplicaciÃ³n:")
    print("  - Cada documento y query se convierte en un vector de 1024 nÃºmeros")
    print("  - Estos nÃºmeros capturan el 'significado' del texto")
    print("  - Textos similares tendrÃ¡n vectores similares")
    print("  - La similaridad se mide con cosine similarity")


def main():
    """
    FunciÃ³n principal
    """
    print("\nğŸ“ HERRAMIENTA DE VISUALIZACIÃ“N DE EMBEDDINGS")
    print("\nElige una opciÃ³n:")
    print("1. Visualizar similaridades de diferentes queries")
    print("2. Comparar queries semÃ¡nticamente similares")
    print("3. Mostrar informaciÃ³n sobre dimensiones")
    print("4. Ejecutar todo")
    
    opcion = input("\nSelecciona (1-4): ").strip()
    
    if opcion == "1":
        visualizar_similaridades()
    elif opcion == "2":
        comparar_queries_similares()
    elif opcion == "3":
        mostrar_dimensiones_embedding()
    elif opcion == "4":
        visualizar_similaridades()
        comparar_queries_similares()
        mostrar_dimensiones_embedding()
    else:
        print("âŒ OpciÃ³n no vÃ¡lida")
    
    print("\n\n" + "=" * 70)
    print("âœ… VISUALIZACIÃ“N COMPLETADA")
    print("=" * 70)
    print("\nğŸ’¡ Para entender mÃ¡s sobre embeddings, lee EMBEDDINGS.md")


if __name__ == "__main__":
    main()
